# Теория вероятностей

Вероятностное пространств состоит из множества всех возможных элементарных исходов, а любое подмножество этих исходов представляет собой случайное событие.

Вероятность случайного события E обозначается P\(E\)

Два события E и F называются **зависимыми**, если знание о наступлении события E, даёт нам какую-то информацию о наступлении события F и наоборот, в противном случае они **независимые**.

С точки зрения математики говорят, что два события E и F независимы, если вероятность их совместного наступления равна произведению вероятностей их наступления по отдельности:

$$
P (E, F) = P (E) * P (F)
$$

## Условная вероятность

Если события E и F зависимы и при этом вероятность события F не равна 0, то условная вероятность события E при условии события F определяется как:

$$
P (E | F) = P (E, F) / P (F)
$$

Попытка вывести формулу выше:

$$
P(E, F) * 1/P(F) = b/c * 1/a/c = b/c * c/a = b/a
$$



Пространство вариантов состоит из **c** исходов. **a** исходов - включают в себя событие P\(F\). **b** исходов - включают в себя одновременно и событие P\(E\) и событие P\(F\). **b** - это подмножество **a**. Если событие P\(F\) произошло, а произойти оно могло через **a** исходов, то значит, что вероятность наступления события P\(E\) в этом случае - это **b/a.**

Из формулы условной вероятности также выводится:

$$
P(E, F) = P(E|F)*P(F)
$$

## Теорема Байеса

Позволяет переставить условные вероятности местами. Общая формулировка: Пусть нужно узнать вероятность некоего события E, зависящего он наступления некоего другого события F, причём нам известна лишь информация о вероятности события F, зависящего от наступления события E.

$$
P(E|F) = P(E, F)/F(F) = P(F|E)P(E)/P(F)
$$

Если событие F разложить на два взаимоисключающих события  - событие "F и E" и событие "F и не E", тогда:

$$
P(F) = P(F, E) + P(F, !E)
$$

В результате формула приводится к итоговому виду:

$$
P(E|F) = \frac {P(F|E)P(E)}{P(F|E)P(E)+P(F|!E)P(!E)}
$$

## Случайные величины

Это переменные, чьим возможным значениям поставлено в соответствие распределение вероятностей. Связанное со случайной величиной распределение вероятностей предоставляет ей вероятности, с которыми она реализует каждое из своих возможных значений.

Среднее ожидаемое значение или математическое ожидание случайной величины - это взвешенная сумма произведений каждого её значения на его вероятность.

Случайне величины могут обуславливаться вероятностью событий.

## Непрерывное распределение

Бросание монеты - это дискретное распределение - оно ставит в соответствие положительную вероятность пронумерованным исходам дискретного вероятностного пространства. 

Однако нередко требуется моделировать распределения на непрерывном пространстве исходов.

Поскольку между 0 и 1 находится бесконечное количество чисел, то значит, вес, который оно назначает индивидуальным точкам, должен с неизбежностью быть равен 0. По этой причине непрерывное распределение расстояния вероятностей представляют плотностью распределения вероятностей \(probability density function, pdf\), также именуемой _дифференциальной функцией распределения \(ДФР\)_, такой, что вероятность наблюдать значение в определённом интервале равна интегралу от дифференциальной функции, взятому в этих пределах.

